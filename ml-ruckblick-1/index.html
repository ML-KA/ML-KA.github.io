<!DOCTYPE html>
<html lang="en">
<head>
          <title>Machine Learning - Karlsruhe</title>
        <meta charset="utf-8" />
        <link href="//ml-ka.de/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Machine Learning - Karlsruhe Full Atom Feed" />
        <link href="//ml-ka.de/feeds/allgemein.atom.xml" type="application/atom+xml" rel="alternate" title="Machine Learning - Karlsruhe Categories Atom Feed" />



    <meta name="tags" content="Allgemein" />

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="//ml-ka.de/">Machine Learning - Karlsruhe <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="//ml-ka.de/pages/about/">About</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="//ml-ka.de/ml-ruckblick-1/" rel="bookmark"
         title="Permalink to ML-Rückblick 1">ML-Rückblick 1</a></h2>
 
  </header>
  <footer class="post-info">
    <abbr class="published" title="2016-02-07T12:00:00+01:00">
      So 07 Februar 2016
    </abbr>
    <address class="vcard author">
      By           <a class="url fn" href="//ml-ka.de/author/martin-thoma.html">Martin Thoma</a>
    </address>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>Der ML-Rückblick gibt einen kurzen Überblick darüber, was seit dem letzen
Rückblick in der Welt des maschinellen Lernens passiert ist.</p>
<h2>New Developments</h2>
<!-- Trends -->

<h3>KogSys Demo</h3>
<p>Auf <a href="https://phiresky.github.io/neural-network-demo/">phiresky.github.io/neural-network-demo</a>
könnt ihr euch schnell mal selbst kleine Netzwerke und Datensätze
zusammenklicken. Dann könnt ihr beobachten, wie sich die Klassifikationsgrenzen
ändern.</p>
<figure style="display:table;margin: 0 auto 0.55em;">
<a href="//ml-ka.de/images/neural-network-kogsys-demo.png"><img align="middle"  width="512" src="//ml-ka.de/images/neural-network-kogsys-demo.png"></a>
<figcaption style="display:table-caption;caption-side:bottom">Interaktive Demo eines neuronalen Netzwerks</figcaption>
</figure>

<h3>HowHot</h3>
<p><a href="https://howhot.io/">howhot.io</a> ist eine Website, auf welcher man Fotos
hochladen kann. Das Programm findet dann ein Gesicht, kategorisiert in
"männlich" oder "weiblich", schätzt das Alter und die Attraktivität. Es gab
ein paar lustige Ergebnisse (siehe <a href="https://www.reddit.com/r/howhot/">Reddit</a>
sowie <a href="https://github.com/MartinThoma/seminar-art-in-machine-learning/tree/master/figures/eth-faces">ein paar weitere Bilder</a>).</p>
<h3>Weitere</h3>
<ul>
<li><a href="http://memorability.csail.mit.edu/">Large-scale Image Memorability</a></li>
</ul>
<h2>Publications</h2>
<!-- e.g. arXiv -->

<h3>AlphaGo</h3>
<figure style="display:table;float:right">
<img style="float:right;" align="middle"  width="256" src="//ml-ka.de/images/go-game.png">
<figcaption style="display:table-caption;caption-side:bottom">Go ist ein Brettspiel für zwei Spieler. Jeder Spieler hat jeweils nur einen Typ von Stein. Pro Zug darf ein Stein auf das 19×19 Feld gelegt werden.<br/>
Bildquelle: <a href="https://commons.wikimedia.org/wiki/File:Go_Regeln_3.png">Wikipedia Commons</a></figcaption>
</figure>

<p>Google hat eine Go-Engine namens AlphaGo entworfen. Diese soll den europäischen
Go-Meister besiegt haben. Bald soll sie gegen den Go-Weltmeister antreten.</p>
<p>Erstaunlich ist, dass man die Go-Engine von Facebook (<a href="http://www.technologyreview.com/view/544181/how-facebooks-ai-researchers-built-a-game-changing-go-engine/?utm_campaign=socialsync&amp;utm_medium=social-post&amp;utm_source=facebook">Link</a>) nicht mal erwähnt.</p>
<p>Quellen und Materialien:</p>
<ul>
<li><a href="http://www.technologyreview.com/news/546066/googles-ai-masters-the-game-of-go-a-decade-earlier-than-expected/">technologyreview.com</a></li>
<li><a href="https://googleblog.blogspot.de/2016/01/alphago-machine-learning-game-go.html">Google Blog Artikel</a></li>
<li><a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html">Nature Artikel</a></li>
<li><a href="https://www.youtube.com/watch?v=g-dKXOlsf98">Nature Video</a></li>
<li>Paper: <a href="https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf">Mastering the Game of Go with Deep Neural Networks and Tree Search</a></li>
</ul>
<h3>Deep Residual Networks</h3>
<p>Microsoft hat mit einem besonders tiefen neuronalen Netzwerk die Microsoft Common Objects in Context (MS COCO) Challenge gewonnen. Das tiefste Netz hat 1202 Schichten.</p>
<p>Materialien:</p>
<ul>
<li>Paper: <a href="http://arxiv.org/abs/1512.03385v1">Deep Residual Learning for Image Recognition</a></li>
<li>Microsoft Blog: <a href="http://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/">Microsoft researchers win ImageNet computer vision challenge</a></li>
</ul>
<h3>Weitere</h3>
<ul>
<li>Thoma: <a href="http://arxiv.org/abs/1601.03642">Creativity in Machine Learning</a>, 2016.</li>
<li>Radford, Metz und Chintala: <a href="http://arxiv.org/abs/1511.06434">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a>, 2015. Es ist auch <a href="https://github.com/Newmu/dcgan_code">Code online</a> verfügbar.</li>
</ul>
<h3>Blog-Artikel</h3>
<ul>
<li>Martin Thoma, 19. Januar 2016: <a href="https://martin-thoma.com/comparing-classifiers/">Comparing Classifiers</a>: Ein kurzer Vergleich verschiedener Klassifikationsalgorithmen auf MNIST und IRIS.</li>
<li>Martin Thoma, 18. Januar 2016: <a href="https://martin-thoma.com/function-approximation/">Function Approximation</a>: Ein sehr kurzes Beispiel, wie man mit gausschen Prozessen Funktionen approximinieren kann.</li>
<li>Zach Dwiel, 15. Januar 2016, <a href="https://github.com/zer0n/deepframeworks/blob/master/README.md">Evaluation of Deep Learning Toolkits</a>: Ein schöner Vergleich zwischen TensorFlow, CNTK, Theano, Torch und Caffe.</li>
<li>Abhinav kumar Gupta, 30. November 2015: <a href="https://www.linkedin.com/pulse/intelligent-photo-ocr-reads-better-than-you-abhinav-kumar-gupta?trk=pulse_spock-articles">Intelligent Photo OCR that reads better than you (Or not)</a></li>
<li>
<ol>
<li>November 2015: <a href="http://www.technologyreview.com/view/543486/single-artificial-neuron-taught-to-recognize-hundreds-of-patterns/?utm_campaign=socialsync&amp;utm_medium=social-post&amp;utm_source=facebook">Single Artificial Neuron Taught to Recognize Hundreds of Patterns</a> (<a href="http://arxiv.org/abs/1511.00083">arxiv</a>)</li>
</ol>
</li>
<li>Mike Schroepfer, 3. November 2015: <a href="https://code.facebook.com/posts/1478523512478471">Teaching machines to see and understand: Advances in AI research</a></li>
<li>Kyle Hill, 22. Juli 2015: <a href="http://nerdist.com/what-happens-when-artificial-intelligence-makes-magic-the-gathering-cards/">What happens when artificial intellicence makes Magic: The Gathering cards</a></li>
<li>Yarin Gal, 3. Juli 2015, <a href="http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html">What My Deep Model Doesn't Know...</a>: Wie kann man die Unsicherheit eines Modells quantifizieren?</li>
<li>Andrej Karpathy, 21. Mai 2015, <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>: Eine Einführung in RNNs. <strong>Sehr Empfehlenswert</strong>. Eine etwas technischere, aber auch sehr gute Einführung ist auf <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">colah.github.io</a></li>
<li>Stephanie Yee und Tony Chu: <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A Visual Introduction to Machine Learning</a></li>
</ul>
<h2>Software</h2>
<!-- e.g. Theano, Keras, ... -->

<ul>
<li>Microsoft veröffentlicht das hauseigene Deep Learning-Toolkit CNTK (<a href="http://blogs.microsoft.com/next/2016/01/25/microsoft-releases-cntk-its-open-source-deep-learning-toolkit-on-github/">Quelle</a>)</li>
<li><a href="https://github.com/nivwusquorum/tensorflow-deepq">Reinforcement Learning using Tensor Flow</a></li>
</ul>
<h2>Interessante Fragen</h2>
<!-- For example StackExchange -->

<ul>
<li>Neural Networks<ul>
<li><a href="https://groups.google.com/forum/#!topic/lasagne-users/2FgZMACnQR4">How important is ECC for Neural Networks?</a></li>
<li><a href="https://www.reddit.com/r/MachineLearning/comments/42gipr/is_it_only_more_computing_power_why_we_can_now/">Is it only more computing power why we can now train deeper networks?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9672/8820">How exactly does adding a new unit work in Cascade Correlation?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9302/8820">The cross-entropy error function in neural networks</a></li>
<li><a href="http://datascience.stackexchange.com/q/8855/8820">Can the size of a pooling layer be learned?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9233/8820">(Why) do activation functions have to be monotonic?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9175/8820">How do subsequent convolution layers work?</a></li>
</ul>
</li>
<li><a href="http://math.stackexchange.com/q/1626052/6876">What are the limitations of linear regression + feature / label transformation?</a></li>
<li><a href="http://stackoverflow.com/q/34648517/562769">How is a digit recognizer trained when using a Markov Random Field?</a></li>
<li>Nomenclature<ul>
<li><a href="http://cs.stackexchange.com/q/51373/2914">What is the difference between 'features' and 'descriptors' in computer vision / machine learning?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9074/8820">Is there a difference between “classification” and “labeling”?</a></li>
<li><a href="http://stackoverflow.com/q/33947823/562769">What is “semantic segmentation” compared to “segmentation” and “scene labeling”?</a></li>
</ul>
</li>
<li><a href="http://cs.stackexchange.com/q/51144/2914">What is the complexity of classification with SVMs?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9172/8820">Can k-means clustering get shells as clusters?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9073/8820">Are all images in ImageNet in the leaves?</a></li>
<li><a href="http://datascience.stackexchange.com/q/10000/8820">What is the difference between a (dynamic) Bayes network and a HMM?</a></li>
</ul>
<h2>Gemischtes</h2>
<ul>
<li>Udacity: <a href="https://www.udacity.com/course/deep-learning--ud730">Deep Learning - Taking machine learning to the next level</a>. Ein Deep Learning Kurs von Google.</li>
<li>Quentin de Laroussilhe: <a href="https://docs.google.com/presentation/d/1O6ozzZHHxGzU-McpvEG09hl7K6oQDd2Taw0FOlnxJc8/preview?slide=id.p">Introduction to machine Learning</a>. Eine sehr kurze Einführung in das maschinelle Lernen.</li>
<li>Daniel Povey: <a href="https://plus.google.com/113952791760990667476/posts/9Hiib9UgUeK">Why simple CNNs with 1x1 kernels may be viewable as learned many-to-many nonlinearities</a>.</li>
<li>Auf <a href="http://www.drivendata.org/">drivendata.org</a> und <a href="http://kaggle.com/">kaggle.com</a> gibt es regelmäßig Wettbewerbe.</li>
<li>Auf <a href="http://robotart.org/">robotart.org</a> gibt es für 2016 einen Wettbewerb.</li>
</ul>
<h2>Klassische Werke</h2>
<!--  -->

<p>Alte Werke wieder in Erinnerung rufen und einen Hauch von Nostalgie spüren, oder aber einfach nur ein Gespür dafür bekommen, was sich in den letzten Jahren und Jahrzehnten so alles getan hat im Bereich Machine Learning - das soll Sinn und Zweck dieses Abschnitts sein.</p>
<p>Dieses mal zum Thema HMM und deren Anwendung in der Spracherkennung:</p>
<p><a href="http://www.ece.ucsb.edu/Faculty/Rabiner/ece259/">Rabiner, Lawrence R.</a>
<em>"A tutorial on hidden Markov models and selected applications in speech recognition."</em>
Proceedings of the IEEE 77.2 (1989): 257-286. <a href="http://dx.doi.org/10.1109/5.18626">DOI: 10.1109/5.18626</a></p>
<h2>Interna</h2>
<!-- About ML-KA itself; can also be a link to posts on this website -->

<h3>AG DANK</h3>
<p>In der DANK-Projektgruppe dreht sich alles um Datenanalyse, Data Mining und natürlich - um Machine Learning. Im Oktober 2015, also gleich zum offiziellen Start unserer Hochschulgruppe haben wir diese Untergruppe ins Leben gerufen. Unser erstes Ziel war die Teilnahme bei dem Datenanalyse-Wettbewerb auf der Herbstagung der Arbeitsgruppe Datenanalyse und Numerische Klassifikation (AG DANK) - daher kommt auch der Name. Die Aufgabe war die Analyse von einer Million Autokonfigurationen, die von Nutzern des Online-Autokonfigurators eines großen deutschen Autobauers erstellt wurden.<br/>
Im November 2015 präsentierte unser sechsköpfiges Team die erarbeiteten Ergebnisse auf der AG DANK Herbsttagung - dabei konnten wir auch gleich unseren ersten Erfolg verbuchen und einen Preis gewinnen.</p>
<p>Unterstützt durch Prof. Geyer-Schulz (KIT) arbeiten wir nun seit Dezember 2015 an einer noch umfangreicheren Analyse des Datensatzes. Zentrale Themen dabei sind Kundensegmentierung, Conjoint-Analyse und das Lernen von Nutzerverhalten.<br/>
In diesem Zusammenhang arbeiten wir an unserem ersten Paper mit dem Titel "Mining consumer-generated product-configuration data", welches wir auf der DAGStat 2016 (14.-18.03.) an der Uni Göttingen präsentieren werden.</p>
<h3>Paper Discussion Group</h3>
<p>Die Paper Discussion Group (PDG) wurde ins Leben gerufen um gemeinsam
wissenschaftliche Veröffentlichungen zu besprechen. Der Gedanke ist, dass man
mehr aus den Veröffentlichungen mitnimmt, wenn man es nicht nur alleine liest,
sondern auch zusammenfasst, anderen erklärt und darüber diskutiert.</p>
<p>Bisher wurden folgende Paper besprochen:</p>
<ol>
<li>Stanford: <a href="http://ufldl.stanford.edu/tutorial/">Deep Learning Tutorial</a></li>
<li>Krizhevsky, Sutskever und Hinton: <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>, 2012. ("AlexNet")</li>
<li>Szegedy et al: <a href="http://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a>, 2014. ("GoogLeNet")</li>
<li>Sermanet et al: <a href="http://arxiv.org/abs/1312.6229">OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a>, 2013.</li>
<li>Nochmals OverFeat</li>
<li>Long, Shelhamer und Darrell: <a href="http://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a>, 2014</li>
<li>Olah: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></li>
<li>Mnih, Heess, Graves, Kavukcuoglu: <a href="http://arxiv.org/abs/1406.6247">Recurrent Models of Visual Attention</a></li>
<li>He, Zhang, Ren und Sun: <a href="http://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
</ol>
<p>Mehr Informationen finden sich auf der
<a href="../paper-discussion-group/">Projektseite</a>.</p>
<h2>Meetings</h2>
<!-- ML-KA meetings, but not only -->

<ul>
<li>Boston, 12. Mai 2016: Deep Learning Summit (<a href="https://www.re-work.co/events/deep-learning-boston-2016">Link</a>)</li>
<li>München, 7. Oktober 2015: Deep Learning in Action #3 (<a href="http://www.meetup.com/de-DE/deeplearning/events/225423302/?eventId=225423302">Link</a>)</li>
</ul>
<!--
<div class="navigation clearfix">
    <div class="alignright">
        <a href="http://ml-ka.de/ml-ruckblick-2/" rel="prev">Nächster Rückblick  »</a>
    </div>
</div>
-->
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>