<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Machine Learning - KIT</title><link href="//ml-ka.github.io/" rel="alternate"></link><link href="//ml-ka.github.io/feeds/projekte.atom.xml" rel="self"></link><id>//ml-ka.github.io/</id><updated>2015-11-11T17:30:00+01:00</updated><entry><title>Paper Discussion Group</title><link href="//ml-ka.github.io/paper-discussion-group/" rel="alternate"></link><updated>2015-11-11T17:30:00+01:00</updated><author><name>Marvin Teichmann</name></author><id>tag:ml-ka.github.io,2015-11-11:paper-discussion-group/</id><summary type="html">&lt;h1 id="erstes-treffen"&gt;Erstes Treffen&lt;/h1&gt;
&lt;p&gt;&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="../images/Cnn_layer.png" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;Schematische Darstellung von CNNs.&lt;br/&gt;
Quelle: Stanford Deep Learning Tutorial&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 11. November, 17:30&lt;/li&gt;
&lt;li&gt;Ort:  Seminarraum: -107, Infobau (Geb. 50.34)&lt;/li&gt;
&lt;li&gt;Thema: Stanford Deep Learning Tutorial&lt;/li&gt;
&lt;li&gt;Experte: Marvin&amp;nbsp;Teichmann&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In dem ersten Treffen m&amp;ouml;chte ich mit euch &amp;uuml;ber das &lt;a href="http://ufldl.stanford.edu/tutorial/"&gt;Deep Learning Tutorial&lt;/a&gt; der Universit&amp;auml;t Stanford sprechen. Dieses gibt einen kompakten sehr guten Einstieg in moderne tiefe CNNs.&lt;/p&gt;
&lt;p&gt;Aufbauend auf dem Tutorial k&amp;ouml;nnen wir in weiteren Treffen &amp;uuml;ber aktuell f&amp;uuml;hrende
Netze, wie &lt;em&gt;AlexNet&lt;/em&gt;[1] oder &lt;em&gt;GoogLeNet&lt;/em&gt; [2] diskutieren. Au&amp;szlig;erdem besteht die
M&amp;ouml;glichkeit, dass wir mit Lasagne einfache Netze selber implementieren.&lt;/p&gt;
&lt;h3 id="vorbereitung"&gt;Vorbereitung&lt;/h3&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch bitte im Vorfeld mit dem &lt;a href="http://ufldl.stanford.edu/tutorial/"&gt;Deep Learning Tutorial&lt;/a&gt; der Universit&amp;auml;t Stanford. Relevante Abschnitte sind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/"&gt;Multi-Layer Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/"&gt;Feature Extraction Using Convolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/Pooling/"&gt;Pooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork"&gt;ConvolutionalNeuralNetwork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/"&gt;Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Das Stanford Tutorial ist recht anspruchsvoll. F&amp;uuml;r ML Einsteiger kann es
hilfreich sein einzelne Schlagw&amp;ouml;rter auch in externen Quellen (zum Beispiel
Wikipedia) nachzulesen. Bitte lasst euch von offenen Fragen oder
Verst&amp;auml;ndnisschwierigkeiten nicht abschrecken. Hierf&amp;uuml;r ist auch die Diskussion
Group da.&lt;/p&gt;
&lt;h1 id="weitere-treffen_1"&gt;Weitere Treffen&lt;/h1&gt;
&lt;p&gt;&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="../images/imagenet.png" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;ImageNet Classification Challenge: &lt;br/&gt;
AlexNet erkennt Katzen!&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Datum: TBA&lt;/li&gt;
&lt;li&gt;Ort:  TBA&lt;/li&gt;
&lt;li&gt;Thema: AlexNet: Die Renaissance der tiefen Neuronalen Netz&lt;/li&gt;
&lt;li&gt;Experte: Marvin Teichmann&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In diesem Treffen m&amp;ouml;chte ich mit euch &amp;uuml;ber &lt;em&gt;AlexNet&lt;/em&gt; reden. &lt;em&gt;AlexNet&lt;/em&gt; ist ein
tiefes Neuronales Netz, welches 2010 &amp;uuml;berraschend die &lt;em&gt;ImageNet Classification
Challenge&lt;/em&gt; gewann. Dies leitete eine Renaissance von Deep Learning ein, welche
bis heute anh&amp;auml;lt. Viele aktuell f&amp;uuml;hrende Netze, wie beispielsweise &lt;em&gt;GoogLeNet&lt;/em&gt;
[2], sind Weiterentwicklungen von &lt;em&gt;AlexNet&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In dem ersten Treffen m&amp;ouml;chte ich mit euch verstehen was &lt;em&gt;AlexNet&lt;/em&gt; so
erfolgreich macht. Wir diskutieren dazu die neuen Ideen zum Trainieren und
Evaluieren des Netzes und untersuchen die neue Netzarchitektur.&lt;/p&gt;
&lt;h3 id="vorbereitung_1"&gt;Vorbereitung&lt;/h3&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch bitte im Vorfeld mit folgender Quelle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Das Paper &amp;uuml;ber &lt;a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf"&gt;AlexNet&lt;/a&gt; [1].&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="ausblick"&gt;Ausblick&lt;/h3&gt;
&lt;p&gt;Aufbauen auf &lt;em&gt;AlexNet&lt;/em&gt; k&amp;ouml;nnen wir im folgenden Treffen &amp;uuml;ber &lt;em&gt;GoogLeNet&lt;/em&gt; reden.
Alternativ ist es m&amp;ouml;glich ein praktisches Treffen zu organisieren bei dem es
darum geht ein Netz selber mit &lt;em&gt;Lasagne&lt;/em&gt; zu Implementieren. Au&amp;szlig;erdem k&amp;ouml;nnen wir
uns mit den neuen &lt;em&gt;FCNN&lt;/em&gt; Ansatz von Jon Long und Evan Shelhamer besch&amp;auml;ftigen.
Wie es konkret weitergeht m&amp;ouml;chte ich am Ende des ersten Treffens mit euch
besprechen.&lt;/p&gt;
&lt;h1 id="literatur-zu-cnns-und-deep-learning_1"&gt;Literatur zu CNNs und Deep-Learning&lt;/h1&gt;
&lt;p&gt;Wer selber mal gerne ein Netz trainieren m&amp;ouml;chte, dem empfehle ich das &lt;a href="http://martin-thoma.com/lasagne-for-python-newbies/"&gt;Lasagne
Tutorial&lt;/a&gt; von Martin
Thoma. F&amp;uuml;r die Paper-Discussion Group ist es allerdings nicht Voraussetzung
bereits praktisch mit CNNs gearbeitet zu haben.&lt;/p&gt;
&lt;h1 id="paper-liste"&gt;Paper Liste&lt;/h1&gt;
&lt;p&gt;Eine Auswahl relevanter Paper zum Thema Deep Learning und Pixel-weiser
Klassifikation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;[AlexNet] ImageNet Classification with Deep Convolutional Neural Networks,
   &lt;em&gt;Alex Krizhevsky et. al&lt;/em&gt; (&lt;strong&gt;NIPS 2012&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;[GoogleLeNet] Going Deeper with Convolutions,
   &lt;em&gt;Szegedy et. al&lt;/em&gt; (&lt;strong&gt;ArXiv 2014&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;[FCNN] Fully Convolutional Networks for Semantic Segmentation,
   &lt;em&gt;Jon Long and Evan Shelhamer et. al&lt;/em&gt; (&lt;strong&gt;CVPR2015&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;[SegNet] SegNet: A Deep Convolutional Encoder-Decoder Architecture for
   Image Segmentation, &lt;em&gt;Vijay Badrinarayanan et. al&lt;/em&gt; (&lt;strong&gt;ArXiv 2015&lt;/strong&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="fragen"&gt;Fragen&lt;/h1&gt;
&lt;p&gt;Beantworte ich gerne. Schreib mir einfach eine kurze E-Mail:
marvxx.teichmaxx@gmaxx.com&lt;/p&gt;</summary><category term="Paper"></category><category term="Deep Learning"></category><category term="Autonomes Fahren"></category></entry></feed>