<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Machine Learning - Karlsruhe</title><link href="//ml-ka.github.io/" rel="alternate"></link><link href="//ml-ka.github.io/feeds/projekte.atom.xml" rel="self"></link><id>//ml-ka.github.io/</id><updated>2015-12-06T09:45:00+01:00</updated><entry><title>Paper Discussion Group</title><link href="//ml-ka.github.io/paper-discussion-group/" rel="alternate"></link><updated>2015-12-06T09:45:00+01:00</updated><author><name>Marvin Teichmann</name></author><id>tag:ml-ka.github.io,2015-12-06:paper-discussion-group/</id><summary type="html">&lt;h1 id="sechstes-treffen"&gt;Sechstes Treffen&lt;/h1&gt;
&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/arma.png" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;&lt;br/&gt;
Lokalisierung von K&amp;ouml;pfen.&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 21.12.2015, 16:15&lt;/li&gt;
&lt;li&gt;Ort:  KIT Biblothek (30.50) R31 (Medienzentrum)&lt;/li&gt;
&lt;li&gt;Thema: Overfeat2: Localization and Detection&lt;/li&gt;
&lt;li&gt;Experte: Michael&amp;nbsp;Weber&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wir besprechen Sektion 4 und 5 von Overfeat.&lt;/p&gt;
&lt;h2 id="vorbereitung"&gt;Vorbereitung&lt;/h2&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch im Vorfeld mit Overfeat:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1312.6229"&gt;Overfeat&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="paper-liste_1"&gt;Paper Liste&lt;/h1&gt;
&lt;p&gt;Eine Auswahl relevanter Paper zum Thema Deep Learning und Pixel-weiser
Klassifikation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;[AlexNet] ImageNet Classification with Deep Convolutional Neural Networks,
   &lt;em&gt;Alex Krizhevsky et. al&lt;/em&gt; (&lt;strong&gt;NIPS 2012&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;[GoogLeNet] Going Deeper with Convolutions,
   &lt;em&gt;Szegedy et. al&lt;/em&gt; (&lt;strong&gt;ArXiv 2014&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;[FCNN] Fully Convolutional Networks for Semantic Segmentation,
   &lt;em&gt;Jon Long and Evan Shelhamer et. al&lt;/em&gt; (&lt;strong&gt;CVPR2015&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;[SegNet] SegNet: A Deep Convolutional Encoder-Decoder Architecture for
   Image Segmentation, &lt;em&gt;Vijay Badrinarayanan et. al&lt;/em&gt; (&lt;strong&gt;ArXiv 2015&lt;/strong&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="weitere-literatur-zu-cnns-und-deep-learning"&gt;Weitere Literatur zu CNNs und Deep-Learning&lt;/h1&gt;
&lt;p&gt;Einsteigern empfehle ich das &lt;a href="http://ufldl.stanford.edu/tutorial/"&gt;Deep Learning Tutorial&lt;/a&gt;der Universit&amp;auml;t Stanford.&lt;/p&gt;
&lt;p&gt;Wer selber mal gerne ein Netz trainieren m&amp;ouml;chte, dem empfehle ich das &lt;a href="http://martin-thoma.com/lasagne-for-python-newbies/"&gt;Lasagne
Tutorial&lt;/a&gt; von Martin
Thoma. F&amp;uuml;r die Paper-Discussion Group ist es allerdings nicht Voraussetzung
bereits praktisch mit CNNs gearbeitet zu haben.&lt;/p&gt;
&lt;h1 id="fragen"&gt;Fragen&lt;/h1&gt;
&lt;p&gt;Beantworte ich gerne. Schreib mir einfach eine kurze E-Mail:
marvxx.teichmaxx@gmaxx.com&lt;/p&gt;
&lt;p&gt;Fragen zu Frameworks k&amp;ouml;nnt ihr Martin stellen: &lt;code&gt;info@martin-thoma.de&lt;/code&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h1 id="vergangene-treffen"&gt;Vergangene Treffen&lt;/h1&gt;
&lt;h2 id="erstes-treffen"&gt;Erstes Treffen&lt;/h2&gt;
&lt;p&gt;&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/Cnn_layer.png" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;Schematische Darstellung von CNNs.&lt;br/&gt;
Quelle: Stanford Deep Learning Tutorial&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 11.11.2015, 17:30&lt;/li&gt;
&lt;li&gt;Ort:  Seminarraum: -107, Infobau (Geb. 50.34)&lt;/li&gt;
&lt;li&gt;Thema: Stanford Deep Learning Tutorial&lt;/li&gt;
&lt;li&gt;Experte: Marvin&amp;nbsp;Teichmann&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In dem ersten Treffen m&amp;ouml;chte ich mit euch &amp;uuml;ber das &lt;a href="http://ufldl.stanford.edu/tutorial/"&gt;Deep Learning Tutorial&lt;/a&gt; der Universit&amp;auml;t Stanford sprechen. Dieses gibt einen kompakten sehr guten Einstieg in moderne tiefe CNNs.&lt;/p&gt;
&lt;p&gt;Aufbauend auf dem Tutorial k&amp;ouml;nnen wir in weiteren Treffen &amp;uuml;ber aktuell f&amp;uuml;hrende
Netze, wie &lt;em&gt;AlexNet&lt;/em&gt; oder &lt;em&gt;GoogLeNet&lt;/em&gt; diskutieren. Au&amp;szlig;erdem besteht die
M&amp;ouml;glichkeit, dass wir mit Lasagne einfache Netze selber implementieren.&lt;/p&gt;
&lt;h3 id="vorbereitung_1"&gt;Vorbereitung&lt;/h3&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch bitte im Vorfeld mit dem &lt;a href="http://ufldl.stanford.edu/tutorial/"&gt;Deep Learning Tutorial&lt;/a&gt; der Universit&amp;auml;t Stanford. Relevante Abschnitte sind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/"&gt;Multi-Layer Neural Network&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/"&gt;Feature Extraction Using Convolution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/Pooling/"&gt;Pooling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork"&gt;ConvolutionalNeuralNetwork&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/"&gt;Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Das Stanford Tutorial ist recht anspruchsvoll. F&amp;uuml;r ML Einsteiger kann es
hilfreich sein einzelne Schlagw&amp;ouml;rter auch in externen Quellen (zum Beispiel
Wikipedia) nachzulesen. Bitte lasst euch von offenen Fragen oder
Verst&amp;auml;ndnisschwierigkeiten nicht abschrecken. Hierf&amp;uuml;r ist auch die Diskussion
Group da.&lt;/p&gt;
&lt;h2 id="zweites-treffen_1"&gt;Zweites Treffen&lt;/h2&gt;
&lt;p&gt;&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/imagenet.png" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;ImageNet Classification Challenge: &lt;br/&gt;
AlexNet erkennt Katzen!&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 25.11.2015, 17:30 - 19:00 Uhr&lt;/li&gt;
&lt;li&gt;Ort: Seminarraum: -107, Infobau (Geb. 50.34)&lt;/li&gt;
&lt;li&gt;Thema: AlexNet: Die Renaissance der tiefen Neuronalen Netz&lt;/li&gt;
&lt;li&gt;Experte: Marvin&amp;nbsp;Teichmann&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In diesem Treffen m&amp;ouml;chte ich mit euch &amp;uuml;ber &lt;em&gt;AlexNet&lt;/em&gt; reden. &lt;em&gt;AlexNet&lt;/em&gt; ist ein
tiefes Neuronales Netz, welches 2010 &amp;uuml;berraschend die &lt;em&gt;ImageNet Classification
Challenge&lt;/em&gt; gewann. Dies leitete eine Renaissance von Deep Learning ein, welche
bis heute anh&amp;auml;lt. Viele aktuell f&amp;uuml;hrende Netze, wie beispielsweise &lt;em&gt;GoogLeNet&lt;/em&gt;, sind Weiterentwicklungen von &lt;em&gt;AlexNet&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In dem zweiten Treffen m&amp;ouml;chte ich mit euch verstehen was &lt;em&gt;AlexNet&lt;/em&gt; so
erfolgreich macht. Wir diskutieren dazu die neuen Ideen zum Trainieren und
Evaluieren des Netzes und untersuchen die neue Netzarchitektur.&lt;/p&gt;
&lt;h3 id="vorbereitung_2"&gt;Vorbereitung&lt;/h3&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch bitte im Vorfeld mit folgender Quelle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf"&gt;AlexNet&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="drittes-treffen_1"&gt;Drittes Treffen&lt;/h2&gt;
&lt;p&gt;&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/a88.jpg" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;Inception module: Ein wichtiges Feature von GoogLeNet&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 02.12.2015, 17:30 - 19:00 Uhr&lt;/li&gt;
&lt;li&gt;Ort:  Seminarraum: -107, Infobau (Geb. 50.34)&lt;/li&gt;
&lt;li&gt;Thema: GoogLeNet: Going Deeper with Convolutions&lt;/li&gt;
&lt;li&gt;Experte: Marvin Teichmann&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In diesem Treffen schauen wir uns &lt;em&gt;GoogLeNet&lt;/em&gt; an. &lt;em&gt;GoogLeNet&lt;/em&gt; basiert auf &lt;em&gt;AlexNet&lt;/em&gt; und enth&amp;auml;lt einige Verbesserungen, die es Google erm&amp;ouml;glicht haben in der ImageNet Challenge 2014 zu f&amp;uuml;hren.&lt;/p&gt;
&lt;p&gt;Im zweiten Teil des Treffens beantworten wir dann erste Fragen die euch beim arbeiten mit dem Tensorflow Tutorial gekommen sind.&lt;/p&gt;
&lt;h2 id="vorbereitung_3"&gt;Vorbereitung&lt;/h2&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch bitte im Vorfeld mit folgender Quelle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1409.4842"&gt;GoogLeNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ml-ka.de/training-your-first-neural-network/"&gt;Tensorflow Session Vorbereitung&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="praktisches-treffen"&gt;Praktisches Treffen&lt;/h2&gt;
&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/tensorFlow.png" style="float:right;" width="128"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;&lt;br/&gt;
Quelle: Wikipedia&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 09.12.2015, 17:30&lt;/li&gt;
&lt;li&gt;Ort:  Seminarraum: -107, Infobau (Geb. 50.34)&lt;/li&gt;
&lt;li&gt;Thema: Implementierung von CNNs mit Tensorflow&lt;/li&gt;
&lt;li&gt;Experte: Martin&amp;nbsp;Thoma&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Das n&amp;auml;chste Treffen wird ein praktisches Treffen. Wir m&amp;ouml;chten uns im Vorfeld mit Tensorflow besch&amp;auml;ftigen und bei dem Treffen das Framework unterhalten.&lt;/p&gt;
&lt;h3 id="vorbereitung_4"&gt;Vorbereitung&lt;/h3&gt;
&lt;p&gt;Zur Vorbereitung tut bitte folgendes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Installiert Python, falls noch nicht vorhanden schaut euch das &lt;a href="https://docs.python.org/2/tutorial/"&gt;offizielle Python 2 tutorial&lt;/a&gt; an.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tensorflow.org/get_started/os_setup.html"&gt;Installiert Tensor Flow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stelle sicher, dass Tensor Flow funktionier (&lt;a href="http://ml-ka.de/training-your-first-neural-network/"&gt;siehe auch&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Bearbeite &lt;a href="http://www.tensorflow.org/tutorials/mnist/beginners/index.html"&gt;MNIST For ML Beginners&lt;/a&gt; tutorial&lt;/li&gt;
&lt;li&gt;Registriere bei Kaggle, und bearbeite &lt;a href="https://www.kaggle.com/c/digit-recognizer"&gt;Digit Recognizer task&lt;/a&gt;. Modifiziere dazu die Implementation von Schritt&amp;nbsp;4&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="funftes-treffen_2"&gt;F&amp;uuml;nftes Treffen&lt;/h1&gt;
&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/woman_bb.png" style="float:right;" width="256"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;&lt;br/&gt;
Lokalisierung eines Kopfes.&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Datum: 16.12.2015, 17:30&lt;/li&gt;
&lt;li&gt;Ort:  Seminarraum: -107, Infobau (Geb. 50.34)&lt;/li&gt;
&lt;li&gt;Thema: Overfeat: Objektlokalisierung mit CNNs&lt;/li&gt;
&lt;li&gt;Experte: Michael&amp;nbsp;Weber&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overfeat erm&amp;ouml;glicht es Objecte (z.b. Autos) auf Bildern zu lokalisieren. Die Aufgabe ist es eine Bounding-Box um das zu Lokalisierende Objekt zu zeichnen.&lt;/p&gt;
&lt;h2 id="vorbereitung_5"&gt;Vorbereitung&lt;/h2&gt;
&lt;p&gt;Besch&amp;auml;ftigt euch im Vorfeld mit Overfeat:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1312.6229"&gt;Overfeat&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Laut Michael ist die Quelle sehr Umfrangreich. Wir werden in der PDG also vermutlich nicht ganz durchkommen. Wer es also nicht schafft das gesammte Paper zu lesen kann trotzdem gerne vorbeikommen.&lt;/p&gt;</summary><category term="Paper"></category><category term="Deep Learning"></category><category term="Autonomes Fahren"></category></entry><entry><title>Training your first Neural Network</title><link href="//ml-ka.github.io/training-your-first-neural-network/" rel="alternate"></link><updated>2015-12-02T21:10:00+01:00</updated><author><name>Martin Thoma</name></author><id>tag:ml-ka.github.io,2015-12-02:training-your-first-neural-network/</id><summary type="html">&lt;p&gt;The following article gives you the necessary knowledge to train and evaluate a
neural network to solve the MNIST task on Kaggle. You will get three
interesting abilities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Working with Tensor Flow&lt;/li&gt;
&lt;li&gt;Working with medium-sized datasets&lt;/li&gt;
&lt;li&gt;Using Kaggle&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Additionally, you will get some knowledge about Python. Python is the language
of my choice when it comes to quickly trying some ideas.&lt;/p&gt;
&lt;h2 id="what-is-mnist"&gt;What is MNIST?&lt;/h2&gt;
&lt;figure style="display:table;float:right"&gt;
&lt;img align="middle" class="img-responsive" src="//ml-ka.github.io/images/mnist-2.png" style="float:right;" width="256px"&gt;
&lt;figcaption style="display:table-caption;caption-side:bottom"&gt;One example of an item in the MNIST dataset - the digit 2&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;
&lt;p&gt;MNIST is a dataset of 28px&amp;nbsp;&amp;times;&amp;nbsp;28px digits. The training set contains
60,000 examples and the test set contains 10,000 examples. If you want to know
more, you can read the &lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;official Website&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="the-framework-tensor-flow"&gt;The Framework: Tensor Flow&lt;/h2&gt;
&lt;p&gt;Tensor Flow is a framework which allows you to train neural networks with GPU,
but also with CPU. I've wrote a couple of words in a blog post:
&lt;a href="http://martin-thoma.com/tensor-flow-quick/"&gt;Tensor Flow - A quick impression&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="using-gpu-at-atis"&gt;Using GPU at ATIS&lt;/h3&gt;
&lt;p&gt;KIT students have the possibility to use the ATIS computer pool. They have
some computer at the very end of the room which have GPUs (i08pc50 - i08pc72;
GeForce GTX 560 Ti 448 Cores).&lt;/p&gt;
&lt;p&gt;Recently, CUDA 7.5 was installed on the Fedora systems, but you still have
to add the following lines to your &lt;code&gt;~/.bashrc&lt;/code&gt; file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;export PATH=$PATH:"/opt/cuda-7.5/bin"
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:"/opt/cuda-7.5/lib64"
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Make sure it appears when you execute &lt;code&gt;echo $PATH&lt;/code&gt; and &lt;code&gt;echo LD_LIBRARY_PATH&lt;/code&gt;.
If it doesn't, execute &lt;code&gt;source ~/.bashrc&lt;/code&gt;. Depending on your configuration,
you might have to do this every time when you start a new console session.&lt;/p&gt;
&lt;p&gt;UPDATE: I've tried it very quickly and it seems not to work out of the box in
ATIS. However, you can sill use your personal computer.&lt;/p&gt;
&lt;p&gt;The error I get is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Traceback &lt;span class="o"&gt;(&lt;/span&gt;most recent call last&lt;span class="o"&gt;)&lt;/span&gt;:
  File &lt;span class="s2"&gt;"tftest.py"&lt;/span&gt;, line 4, in &amp;lt;module&amp;gt;
    import tensorflow as tf
  File &lt;span class="s2"&gt;"/home/stud/s_thoma/.local/lib/python2.7/site-packages/tensorflow/__init__.py"&lt;/span&gt;, line 4, in &amp;lt;module&amp;gt;
    from tensorflow.python import *
  File &lt;span class="s2"&gt;"/home/stud/s_thoma/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"&lt;/span&gt;, line 22, in &amp;lt;module&amp;gt;
    from tensorflow.python.client.client_lib import *
  File &lt;span class="s2"&gt;"/home/stud/s_thoma/.local/lib/python2.7/site-packages/tensorflow/python/client/client_lib.py"&lt;/span&gt;, line 35, in &amp;lt;module&amp;gt;
    from tensorflow.python.client.session import InteractiveSession
  File &lt;span class="s2"&gt;"/home/stud/s_thoma/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"&lt;/span&gt;, line 11, in &amp;lt;module&amp;gt;
    from tensorflow.python import pywrap_tensorflow as tf_session
  File &lt;span class="s2"&gt;"/home/stud/s_thoma/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"&lt;/span&gt;, line 28, in &amp;lt;module&amp;gt;
    &lt;span class="nv"&gt;_pywrap_tensorflow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; swig_import_helper&lt;span class="o"&gt;()&lt;/span&gt;
  File &lt;span class="s2"&gt;"/home/stud/s_thoma/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"&lt;/span&gt;, line 24, in swig_import_helper
    &lt;span class="nv"&gt;_mod&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; imp.load_module&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'_pywrap_tensorflow'&lt;/span&gt;, fp, pathname, description&lt;span class="o"&gt;)&lt;/span&gt;
ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="what-is-kaggle_1"&gt;What is Kaggle?&lt;/h2&gt;
&lt;p&gt;Kaggle is a Machine Learning competition website. It describes tasks in a very
simple way, provides the data and lets you instantly compare yourself (or
rather your results) with others. With this article, you should be able to make
a decent submission for the
&lt;a href="https://www.kaggle.com/c/digit-recognizer"&gt;Digit Recognizer&lt;/a&gt; task.&lt;/p&gt;
&lt;h2 id="what-to-do"&gt;What to do&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Get a Python installation and get a feeling how Python works. If you didn't
   use Python before, I suggest reading chapters 1-5 of the
   &lt;a href="https://docs.python.org/2/tutorial/"&gt;official Python 2 tutorial&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.tensorflow.org/get_started/os_setup.html"&gt;Install Tensor Flow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Make sure Tensor Flow works&lt;/li&gt;
&lt;li&gt;Read the &lt;a href="http://www.tensorflow.org/tutorials/mnist/beginners/index.html"&gt;MNIST For ML Beginners&lt;/a&gt; tutorial&lt;/li&gt;
&lt;li&gt;Register at Kaggle, download the data for the
   &lt;a href="https://www.kaggle.com/c/digit-recognizer"&gt;Digit Recognizer task&lt;/a&gt;, adjust
   your implementation from step&amp;nbsp;5 and make a submission to Kaggle.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="questions"&gt;Questions&lt;/h2&gt;
&lt;h3 id="how-do-i-get-python"&gt;How do I get Python?&lt;/h3&gt;
&lt;p&gt;I have to admit that I always worked on systems which already had a running
Python installation. This is one reason why I really like working with
Ubuntu (Linux). You only have to execute &lt;code&gt;sudo apt-get install python-pip&lt;/code&gt; and
you're ready to go.&lt;/p&gt;
&lt;p&gt;The official page is &lt;a href="https://www.python.org/downloads/"&gt;www.python.org/downloads&lt;/a&gt;.
If you're having trouble getting a working Python installation, don't hesitate
to ask for help.&lt;/p&gt;
&lt;h3 id="how-do-i-check-if-my-python-installation-is-working"&gt;How do I check if my Python installation is working?&lt;/h3&gt;
&lt;p&gt;Go to the command line and execute &lt;code&gt;python --version&lt;/code&gt;. My output is &lt;code&gt;Python 2.7.6&lt;/code&gt;.
As long as you get something like &lt;code&gt;Python 2.7.X&lt;/code&gt; it is ok. Tensor Flow works
only with Python&amp;nbsp;2, not with Python&amp;nbsp;3.&lt;/p&gt;
&lt;p&gt;Then execute &lt;code&gt;pip --version&lt;/code&gt;. It should output something like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;
&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="mf"&gt;6.0.6&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python2&lt;/span&gt;&lt;span class="mf"&gt;.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;6.0.6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;py2&lt;/span&gt;&lt;span class="mf"&gt;.7&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;egg&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;pip is a package manager for Python. You might need it to install several
packages, including Tensor Flow.&lt;/p&gt;
&lt;h3 id="how-do-i-make-sure-tensor-flow-works"&gt;How do I make sure Tensor Flow works?&lt;/h3&gt;
&lt;p&gt;Create a &lt;code&gt;testtf.py&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="n"&gt;hello&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'Hello, TensorFlow!'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Execute it with the command &lt;code&gt;python testtf.py&lt;/code&gt;. For me, the output is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 12
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:888] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:88] Found device 0 with properties: 
name: GeForce GTX TITAN Black
major: 3 minor: 5 memoryClockRate (GHz) 0.98
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.77GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:112] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:122] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:0) -&amp;gt; (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 5884919808
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 12
Hello, TensorFlow!
42
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The important part is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Hello, TensorFlow!
42
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;if you don't get that, there is something wrong.&lt;/p&gt;</summary><category term="Deep Learning"></category><category term="MNIST"></category><category term="Tensor Flow"></category></entry><entry><title>Kaggle 1</title><link href="//ml-ka.github.io/kaggle-1/" rel="alternate"></link><updated>2015-12-01T19:40:00+01:00</updated><author><name>Duc Tam Nguyen</name></author><id>tag:ml-ka.github.io,2015-12-01:kaggle-1/</id><summary type="html">&lt;p&gt;Lasst uns nicht nur neues Wissen aneignen sondern dies sinnvoll einsetzen! Die
&lt;a href="https://www.kaggle.com/c/rossmann-store-sales"&gt;Rossmann Stores Challenge&lt;/a&gt;
l&amp;auml;uft zwar nur bis 14.12.2015, aber sie soll uns helfen in Fahrt zu kommen.
Guckt euch bitte die Aufgabe vorher an, und bringe Ideen mit.&lt;/p&gt;
&lt;p&gt;Es kam die Idee auf dass wir uns w&amp;ouml;chentlich treffen um langfristig etwas zu
erreichen. Das k&amp;ouml;nnen wir beim Treffen auch gleich besprechen.&lt;/p&gt;
&lt;p&gt;Ich freue mich auf euch.&lt;/p&gt;
&lt;h2 id="organisatorisches"&gt;Organisatorisches&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Wann?&lt;/strong&gt; Mittwoch, 2.&amp;nbsp;Dezember&amp;nbsp;2015, 20:00&amp;ndash;22:00&amp;nbsp;Uhr&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wo?&lt;/strong&gt; Seminarraum&amp;nbsp;-118, Infobau (Geb.&amp;nbsp;50.34)&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Kaggle"></category><category term="Rossmann"></category><category term="Data Science"></category></entry></feed>