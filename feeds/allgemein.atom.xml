<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Machine Learning - Karlsruhe</title><link href="//ml-ka.github.io/" rel="alternate"></link><link href="//ml-ka.github.io/feeds/allgemein.atom.xml" rel="self"></link><id>//ml-ka.github.io/</id><updated>2015-06-15T10:20:00+02:00</updated><entry><title>Machine Learning Grundlagen</title><link href="//ml-ka.github.io/machine-learning-grundlagen/" rel="alternate"></link><updated>2015-06-15T10:20:00+02:00</updated><author><name>Martin Thoma</name></author><id>tag:ml-ka.github.io,2015-06-15:machine-learning-grundlagen/</id><summary type="html">&lt;p&gt;Im folgenden werden Grundlagen des maschinellen Lernens erkl&amp;auml;rt.&lt;/p&gt;
&lt;h2 id="was-ist-maschinelles-lernen"&gt;Was ist maschinelles Lernen?&lt;/h2&gt;
&lt;p&gt;Beim maschinellen Lernen geht es darum einen Algorithmus zu schreiben, der mit
Daten lernt was relevant ist. Der Algorithmus kennt also eine allgemeine
Struktur, wo er Teile anpassen kann, sodass eine Aufgabe "m&amp;ouml;glichst gut"
erf&amp;uuml;llt wird. Was "m&amp;ouml;glichst gut" bedeutet, muss der Programmierer festlegen.&lt;/p&gt;
&lt;p&gt;Tom Mitchel hat maschinelles Lernen wie folgt Definiert:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A computer program is said to learn from experience &lt;span class="math"&gt;\(E\)&lt;/span&gt; with respect to some
class of tasks &lt;span class="math"&gt;\(T\)&lt;/span&gt; and performance measure &lt;span class="math"&gt;\(P\)&lt;/span&gt;, if its performance at tasks
in &lt;span class="math"&gt;\(T\)&lt;/span&gt;, as measured by &lt;span class="math"&gt;\(P\)&lt;/span&gt;, improves with experience &lt;span class="math"&gt;\(E\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="ein-beispiel"&gt;Ein Beispiel&lt;/h2&gt;
&lt;p&gt;Angenommen man hat eine &lt;a href="https://de.wikipedia.org/wiki/Schwertlilien"&gt;Schwertlilie&lt;/a&gt;.
Es ist klar, dass es eine Schwertlilie ist, aber es k&amp;ouml;nnte entweder eine
Iris Setosa, eine Iris Virginica oder eine Iris Versicolor sein. Man muss nun
ein Programm schreiben, welches die 3 Arten von einander unterscheiden kann.
Der Einfachheit halber werden diese im Folgenden als Klasse I, II und III
bezeichnet.&lt;/p&gt;
&lt;p&gt;Biologen haben f&amp;uuml;r je 50 konkrete Pflanzen (Instanzen der drei Arten) vier
Gr&amp;ouml;&amp;szlig;en gemessen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://de.wikipedia.org/wiki/Kelchblatt"&gt;Kelchblatt&lt;/a&gt;: L&amp;auml;nge und H&amp;ouml;he, in cm.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://de.wikipedia.org/wiki/Kronblatt"&gt;Kronblatt&lt;/a&gt;: L&amp;auml;nge und H&amp;ouml;he, in cm.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wie kann man diese Information nun nutzen um zu lernen, was eine Iris
Versicolor von einer Iris Virginica unterscheidet?&lt;/p&gt;
&lt;p&gt;Der einfachste Ansatz w&amp;auml;re die Daten f&amp;uuml;r einfache Klassifikatoren zu
betrachten. Vielleicht hat Klasse I ja immer eine deutlich kleinere
Kelchblattgr&amp;ouml;&amp;szlig;e. Oder vielleicht ist das Verh&amp;auml;ltnis zwischen Kelchblattl&amp;auml;nge
und Kelchblattbreite deutlich unterschiedlich bei den Arten.&lt;/p&gt;
&lt;p&gt;Das w&amp;auml;re eine einfache L&amp;ouml;sung f&amp;uuml;r dieses Klassifikationsproblem.&lt;/p&gt;
&lt;!-- ## Klassifikatoren vergleichen

Natürlich gibt es viele weitere Möglichkeiten das Klassifikationsproblem zu
lösen. Und wir wollen die beste finden. Aber was ist die beste Möglichkeit?
Dafür muss man eine Fehlerfunktion haben.  --&gt;
&lt;h2 id="decision-trees"&gt;Decision Trees&lt;/h2&gt;
&lt;p&gt;TODO: Kurz erkl&amp;auml;ren, damit es sp&amp;auml;ter verwendet werden kann.&lt;/p&gt;
&lt;h2 id="vorgehen"&gt;Vorgehen&lt;/h2&gt;
&lt;p&gt;Es gibt jedoch auch kompliziertere L&amp;ouml;sungen wie decision trees, Support Vector
Machines (SVMs) und neuronale Netze. Diese haben interne Parameter, welche
angepasst werden um eine L&amp;ouml;sung zu finden. Bei allen diesen Klassifikatoren
kann man zwischen &lt;em&gt;Training&lt;/em&gt; und &lt;em&gt;Evaluation&lt;/em&gt; unterscheiden. Beim Training
lernt der Klassifikator was wichtig ist und in der Evaluation wendet er es an.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Training / Validation / Development / Testset&lt;/li&gt;
&lt;li&gt;Hyperparameter&lt;/li&gt;
&lt;li&gt;Datengetriebene Entwicklung&lt;/li&gt;
&lt;li&gt;Overfitting&lt;/li&gt;
&lt;li&gt;Supervised &amp;lt;-&amp;gt; unsupervised&lt;/li&gt;
&lt;li&gt;Classification, Regression&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="abgrenzung"&gt;Abgrenzung&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning &amp;lt;-&amp;gt; A.I. &amp;lt;-&amp;gt; Data science &amp;lt;-&amp;gt; Statistik &amp;lt;-&amp;gt; Big Data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Als &lt;/p&gt;
&lt;h2 id="siehe-auch"&gt;Siehe auch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Statistical_classification"&gt;Statistical classification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Allgemein"></category><category term="Klassifikation"></category><category term="Iris dataset"></category></entry><entry><title>Materialsammlung</title><link href="//ml-ka.github.io/materialsammlung/" rel="alternate"></link><updated>2015-06-15T10:20:00+02:00</updated><author><name>Martin Thoma</name></author><id>tag:ml-ka.github.io,2015-06-15:materialsammlung/</id><summary type="html">&lt;p&gt;Hier k&amp;ouml;nnen wir interessante Artikel, Websiten oder allgemein Materialien
sammeln. Wem das noch zu wenig ist oder wer selbst gute Materialien f&amp;uuml;r diese
Seite vorschlagen will, der kann dies &amp;uuml;ber &lt;a href="https://github.com/ML-KA/ML-KA.github.io/issues/6"&gt;GitHub&lt;/a&gt;
tun.&lt;/p&gt;
&lt;h2 id="artikel"&gt;Artikel&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://hunch.net/?p=22"&gt;Clever Methods of Overfitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scott.fortmann-roe.com/docs/BiasVariance.html"&gt;Understanding the Bias-Variance Tradeoff&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="bucher"&gt;B&amp;uuml;cher&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://neuralnetworksanddeeplearning.com/"&gt;Neural Networks and Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="moocs"&gt;MOOCs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Coursera: &lt;a href="https://www.coursera.org/learn/machine-learning"&gt;Machine Learning&lt;/a&gt; by Andrew Ng&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.stanford.edu/"&gt;CS224d: Deep Learning for Natural Language Processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/"&gt;Machine Learning&lt;/a&gt;: Kurs der Universit&amp;auml;t Oxford&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs231n.stanford.edu/"&gt;Convolutional Neural Networks for Visual Recognition&lt;/a&gt;: Kurs von Stanford&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tools"&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt;: C++ and Python, supports nVidia GPU training of neural networks&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Lasagne/Lasagne"&gt;Lasagne&lt;/a&gt;: Python, supports nVidia GPU training of neural networks&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/"&gt;sklearn&lt;/a&gt;: Python Machine learning toolkit&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="datensatze"&gt;Datens&amp;auml;tze&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;MNIST&lt;/a&gt;: 70 000 Bilder der Gr&amp;ouml;&amp;szlig;e 28x28 mit Labels (Ziffern 0-9)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://archive.ics.uci.edu/ml/datasets/Iris"&gt;IRIS&lt;/a&gt;: 3 Klassen, 50 Datens&amp;auml;tze pro Klasse, 3 Features pro Datensatz&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.martin-thoma.de/write-math/data/"&gt;HWRT&lt;/a&gt;: Handgeschriebene Symbole&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cvlibs.net/datasets/kitti/"&gt;KITTI&lt;/a&gt;: Road vision dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Listen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.computervisiononline.com/datasets"&gt;computervisiononline.com&lt;/a&gt;: Eine Liste sehr vieler Datens&amp;auml;tze&lt;/li&gt;
&lt;li&gt;&lt;a href="http://riemenschneider.hayko.at/vision/dataset/"&gt;YACVID&lt;/a&gt;: Computer Vision Index To Datasets&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.dmoz.org/Computers/Artificial_Intelligence/Machine_Learning/Datasets/"&gt;dmoz.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cheat-cheats"&gt;Cheat Cheats&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/"&gt;Choosing the right estimator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://azure.microsoft.com/en-in/documentation/articles/machine-learning-algorithm-cheat-sheet/"&gt;Machine learning algorithm cheat sheet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="lists"&gt;Lists&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/ujjwalkarn/Machine-Learning-Tutorials"&gt;Machine Learning Tutorials&lt;/a&gt; by Ujjwal Karn (Facebook employee)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jiwonkim.org/awesome-random-forest/"&gt;Awesome Random Forest&lt;/a&gt;: A
  curated list of resources regarding tree-based methods and more, including
  but not limited to random forest, bagging and boosting.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="sonstiges"&gt;Sonstiges&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt;: Machine Learning Wettbewerbe&lt;/li&gt;
&lt;li&gt;Stack Exchange&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datascience.stackexchange.com/"&gt;datascience.stackexchange.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/"&gt;stats.stackexchange.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/josephmisiti/awesome-machine-learning"&gt;awesome-machine-learning&lt;/a&gt;: Eine Liste mit VIELEN Links zu Machine Learning Tools.&lt;/li&gt;
&lt;li&gt;Demos:&lt;/li&gt;
&lt;li&gt;&lt;a href="http://104.131.78.120/"&gt;Neural Machine Translation&lt;/a&gt;: Englisch &amp;rarr; Deutsch, Franz&amp;ouml;sisch&lt;/li&gt;
&lt;li&gt;&lt;a href="http://write-math.com"&gt;write-math.com&lt;/a&gt;: Symbolerkennung&lt;/li&gt;
&lt;/ul&gt;</summary><category term="Allgemein"></category></entry></feed>