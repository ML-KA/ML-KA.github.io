<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>Paper Discussion Group - Machine Learning - Karlsruhe</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">



<link rel="canonical" href="//ml-ka.de/paper-discussion-group/">

        <meta name="author" content="Marvin Teichmann, Martin Thoma" />
        <meta name="keywords" content="Paper,Deep Learning,Autonomes Fahren" />
        <meta name="description" content="14. Treffen Datum: 26.02.2016, 17:30 Ort: Seminarraum 131, Infobau (Geb. 50.34) Thema: Deep Networks with Stochastic Depth Experte: Martin Thoma (Zusammenfassung) Kommende Paper Gesichtserkennung DeepFace: Closing the Gap to Human-Level Performance in Face Verification (Facebook) FaceNet: A Unified Embedding for Face Recognition and Clustering (Google) A ..." />

        <meta property="og:site_name" content="Machine Learning - Karlsruhe" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="Paper Discussion Group"/>
        <meta property="og:url" content="//ml-ka.de/paper-discussion-group/"/>
        <meta property="og:description" content="14. Treffen Datum: 26.02.2016, 17:30 Ort: Seminarraum 131, Infobau (Geb. 50.34) Thema: Deep Networks with Stochastic Depth Experte: Martin Thoma (Zusammenfassung) Kommende Paper Gesichtserkennung DeepFace: Closing the Gap to Human-Level Performance in Face Verification (Facebook) FaceNet: A Unified Embedding for Face Recognition and Clustering (Google) A ..."/>
        <meta property="article:published_time" content="2016-01-09" />
            <meta property="article:section" content="Projekte" />
            <meta property="article:tag" content="Paper" />
            <meta property="article:tag" content="Deep Learning" />
            <meta property="article:tag" content="Autonomes Fahren" />
            <meta property="article:author" content="Marvin Teichmann" />


    <!-- Bootstrap -->
        <link rel="stylesheet" href="//ml-ka.de/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="//ml-ka.de/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="//ml-ka.de/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="//ml-ka.de/theme/css/style.css" type="text/css"/>

        <link href="//ml-ka.de/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="Machine Learning - Karlsruhe ATOM Feed"/>



        <link href="//ml-ka.de/feeds/projekte.atom.xml" type="application/atom+xml" rel="alternate"
              title="Machine Learning - Karlsruhe Projekte ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="//ml-ka.de/" class="navbar-brand">
Machine Learning - Karlsruhe            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="//ml-ka.de/pages/about/">
                             About
                          </a></li>
                        <li >
                            <a href="//ml-ka.de/category/allgemein/">Allgemein</a>
                        </li>
                        <li >
                            <a href="//ml-ka.de/category/kit/">KIT</a>
                        </li>
                        <li class="active">
                            <a href="//ml-ka.de/category/projekte/">Projekte</a>
                        </li>
                        <li >
                            <a href="//ml-ka.de/category/veranstaltungen/">Veranstaltungen</a>
                        </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              <li><a href="//ml-ka.de/archives.html"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="//ml-ka.de/paper-discussion-group/"
                       rel="bookmark"
                       title="Permalink to Paper Discussion Group">
                        Paper Discussion Group
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2016-01-09T09:45:00+01:00"> Sa 09 Januar 2016</time>
    </span>





<span class="label label-default">Tags</span>
	<a href="//ml-ka.de/tag/paper/">Paper</a>
        /
	<a href="//ml-ka.de/tag/deep-learning/">Deep Learning</a>
        /
	<a href="//ml-ka.de/tag/autonomes-fahren/">Autonomes Fahren</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <h1 id="14-treffen">14. Treffen</h1>
<ul>
<li>Datum: 26.02.2016, 17:30</li>
<li>Ort: Seminarraum 131, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://arxiv.org/abs/1603.09382">Deep Networks with Stochastic Depth</a></li>
<li>Experte: Martin&nbsp;Thoma (<a href="http://www.shortscience.org/paper?bibtexKey=huang2016networks#MartinThoma">Zusammenfassung</a>)</li>
</ul>
<h1 id="kommende-paper">Kommende Paper</h1>
<ul>
<li>Gesichtserkennung<ul>
<li><a href="https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf">DeepFace: Closing the Gap to Human-Level Performance in Face Verification</a> (Facebook)</li>
<li><a href="http://arxiv.org/abs/1503.03832">FaceNet: A Unified Embedding for Face Recognition and Clustering</a> (Google)</li>
<li><a href="http://arxiv.org/abs/1511.02683v1">A Lightened CNN for Deep Face Representation</a></li>
</ul>
</li>
<li><a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=5947610">Structured Output Layer Neural Network Language Models for Speech Recognition</a></li>
<li><a href="http://arxiv.org/abs/1506.03340">Teaching Machines to Read and Comprehend</a></li>
<li><a href="http://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
<li><a href="http://arxiv.org/pdf/1502.03044v2.pdf">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a> (Soft attention)</li>
<li>Knowledge transfer<ul>
<li><a href="http://arxiv.org/abs/1411.1792">How transferable are features in deep neural networks</a></li>
<li><a href="http://arxiv.org/abs/1504.04871">DEEP-CARVING: Discovering Visual Attributes by Carving Deep Neural Nets</a></li>
<li><a href="http://arxiv.org/abs/1506.00511">Predicting Deep Zero-Shot Convolutional Neural Networks using Textual Descriptions</a></li>
<li><a href="http://arxiv.org/abs/1502.02791">Learning Transferable Features with Deep Adaptation Networks</a></li>
</ul>
</li>
<li>Reinforcement Learning<ul>
<li><a href="http://arxiv.org/abs/1602.01783v1">Asynchronous Methods for Deep Reinforcement Learning</a></li>
<li><a href="http://arxiv.org/abs/1511.06342">Actor mimic: Deep multitask and transfer reinforcement learning</a></li>
<li><a href="http://arxiv.org/abs/1509.06461v3">Deep Reinforcement Learning with Double Q-learning</a></li>
</ul>
</li>
</ul>
<h1 id="paper-liste">Paper Liste</h1>
<p>Eine Auswahl relevanter Paper zum Thema Deep Learning und Pixel-weiser
Klassifikation.</p>
<ol>
<li>[AlexNet] ImageNet Classification with Deep Convolutional Neural Networks,
   <em>Alex Krizhevsky et. al</em> (<strong>NIPS 2012</strong>)</li>
<li>[GoogLeNet] Going Deeper with Convolutions,
   <em>Szegedy et. al</em> (<strong>ArXiv 2014</strong>)</li>
<li>[FCNN] Fully Convolutional Networks for Semantic Segmentation,
   <em>Jon Long and Evan Shelhamer et. al</em> (<strong>CVPR2015</strong>)</li>
<li>[SegNet] SegNet: A Deep Convolutional Encoder-Decoder Architecture for
   Image Segmentation, <em>Vijay Badrinarayanan et. al</em> (<strong>ArXiv 2015</strong>)</li>
</ol>
<h1 id="weitere-literatur-zu-cnns-und-deep-learning">Weitere Literatur zu CNNs und Deep-Learning</h1>
<p>Einsteigern empfehle ich das <a href="http://ufldl.stanford.edu/tutorial/">Deep Learning Tutorial</a>der Universit&auml;t Stanford.</p>
<p>Wer selber mal gerne ein Netz trainieren m&ouml;chte, dem empfehle ich das <a href="http://martin-thoma.com/lasagne-for-python-newbies/">Lasagne
Tutorial</a> von Martin
Thoma. F&uuml;r die Paper-Discussion Group ist es allerdings nicht Voraussetzung
bereits praktisch mit CNNs gearbeitet zu haben.</p>
<h1 id="fragen">Fragen</h1>
<p>Beantworte ich gerne. Schreib mir einfach eine kurze E-Mail:
marvxx.teichmaxx@gmaxx.com</p>
<p>Fragen zu Frameworks k&ouml;nnt ihr Martin stellen: <code>info@martin-thoma.de</code></p>
<hr/>
<h1 id="vergangene-treffen">Vergangene Treffen</h1>
<h2 id="erstes-treffen">Erstes Treffen</h2>
<p><figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/Cnn_layer.png" style="float:right;" width="256">
<figcaption style="display:table-caption;caption-side:bottom">Schematische Darstellung von CNNs.<br/>
Quelle: Stanford Deep Learning Tutorial</figcaption>
</img></figure></p>
<ul>
<li>Datum: 11.11.2015, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: Stanford Deep Learning Tutorial</li>
<li>Experte: Marvin&nbsp;Teichmann</li>
</ul>
<p>In dem ersten Treffen m&ouml;chte ich mit euch &uuml;ber das <a href="http://ufldl.stanford.edu/tutorial/">Deep Learning Tutorial</a> der Universit&auml;t Stanford sprechen. Dieses gibt einen kompakten sehr guten Einstieg in moderne tiefe CNNs.</p>
<p>Aufbauend auf dem Tutorial k&ouml;nnen wir in weiteren Treffen &uuml;ber aktuell f&uuml;hrende
Netze, wie <em>AlexNet</em> oder <em>GoogLeNet</em> diskutieren. Au&szlig;erdem besteht die
M&ouml;glichkeit, dass wir mit Lasagne einfache Netze selber implementieren.</p>
<h3 id="vorbereitung">Vorbereitung</h3>
<p>Besch&auml;ftigt euch bitte im Vorfeld mit dem <a href="http://ufldl.stanford.edu/tutorial/">Deep Learning Tutorial</a> der Universit&auml;t Stanford. Relevante Abschnitte sind:</p>
<ul>
<li><a href="http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/">Multi-Layer Neural Network</a></li>
<li><a href="http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/">Feature Extraction Using Convolution</a></li>
<li><a href="http://ufldl.stanford.edu/tutorial/supervised/Pooling/">Pooling</a></li>
<li><a href="http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork">ConvolutionalNeuralNetwork</a></li>
<li><a href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/">Autoencoders</a></li>
</ul>
<p>Das Stanford Tutorial ist recht anspruchsvoll. F&uuml;r ML Einsteiger kann es
hilfreich sein einzelne Schlagw&ouml;rter auch in externen Quellen (zum Beispiel
Wikipedia) nachzulesen. Bitte lasst euch von offenen Fragen oder
Verst&auml;ndnisschwierigkeiten nicht abschrecken. Hierf&uuml;r ist auch die Diskussion
Group da.</p>
<h2 id="zweites-treffen_1">Zweites Treffen</h2>
<p><figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/imagenet.png" style="float:right;" width="256">
<figcaption style="display:table-caption;caption-side:bottom">ImageNet Classification Challenge: <br/>
AlexNet erkennt Katzen!</figcaption>
</img></figure></p>
<ul>
<li>Datum: 25.11.2015, 17:30 - 19:00 Uhr</li>
<li>Ort: Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: AlexNet: Die Renaissance der tiefen Neuronalen Netz</li>
<li>Experte: Marvin&nbsp;Teichmann</li>
</ul>
<p>In diesem Treffen m&ouml;chte ich mit euch &uuml;ber <em>AlexNet</em> reden. <em>AlexNet</em> ist ein
tiefes Neuronales Netz, welches 2010 &uuml;berraschend die <em>ImageNet Classification
Challenge</em> gewann. Dies leitete eine Renaissance von Deep Learning ein, welche
bis heute anh&auml;lt. Viele aktuell f&uuml;hrende Netze, wie beispielsweise <em>GoogLeNet</em>, sind Weiterentwicklungen von <em>AlexNet</em>.</p>
<p>In dem zweiten Treffen m&ouml;chte ich mit euch verstehen was <em>AlexNet</em> so
erfolgreich macht. Wir diskutieren dazu die neuen Ideen zum Trainieren und
Evaluieren des Netzes und untersuchen die neue Netzarchitektur.</p>
<h3 id="vorbereitung_1">Vorbereitung</h3>
<p>Besch&auml;ftigt euch bitte im Vorfeld mit folgender Quelle:</p>
<ol>
<li><a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">AlexNet</a></li>
</ol>
<h2 id="drittes-treffen_1">Drittes Treffen</h2>
<p><figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/a88.jpg" style="float:right;" width="256">
<figcaption style="display:table-caption;caption-side:bottom">Inception module: Ein wichtiges Feature von GoogLeNet</figcaption>
</img></figure></p>
<ul>
<li>Datum: 02.12.2015, 17:30 - 19:00 Uhr</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: GoogLeNet: Going Deeper with Convolutions</li>
<li>Experte: Marvin Teichmann</li>
</ul>
<p>In diesem Treffen schauen wir uns <em>GoogLeNet</em> an. <em>GoogLeNet</em> basiert auf <em>AlexNet</em> und enth&auml;lt einige Verbesserungen, die es Google erm&ouml;glicht haben in der ImageNet Challenge 2014 zu f&uuml;hren.</p>
<p>Im zweiten Teil des Treffens beantworten wir dann erste Fragen die euch beim arbeiten mit dem Tensorflow Tutorial gekommen sind.</p>
<h3 id="vorbereitung_2">Vorbereitung</h3>
<p>Besch&auml;ftigt euch bitte im Vorfeld mit folgender Quelle:</p>
<ol>
<li><a href="http://arxiv.org/abs/1409.4842">GoogLeNet</a></li>
<li><a href="http://ml-ka.de/training-your-first-neural-network/">Tensorflow Session Vorbereitung</a></li>
</ol>
<h2 id="viertes-treffen-praktisches-treffen_1">Viertes Treffen (Praktisches Treffen)</h2>
<figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/tensorFlow.png" style="float:right;" width="128">
<figcaption style="display:table-caption;caption-side:bottom"><br/>
Quelle: Wikipedia</figcaption>
</img></figure>
<ul>
<li>Datum: 09.12.2015, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: Implementierung von CNNs mit Tensorflow</li>
<li>Experte: Martin&nbsp;Thoma</li>
</ul>
<p>Das n&auml;chste Treffen wird ein praktisches Treffen. Wir m&ouml;chten uns im Vorfeld mit Tensorflow besch&auml;ftigen und bei dem Treffen das Framework unterhalten.</p>
<h3 id="vorbereitung_3">Vorbereitung</h3>
<p>Zur Vorbereitung tut bitte folgendes:</p>
<ol>
<li>Installiert Python, falls noch nicht vorhanden schaut euch das <a href="https://docs.python.org/2/tutorial/">offizielle Python 2 tutorial</a> an.</li>
<li><a href="http://www.tensorflow.org/get_started/os_setup.html">Installiert Tensor Flow</a></li>
<li>Stelle sicher, dass Tensor Flow funktionier (<a href="http://ml-ka.de/training-your-first-neural-network/">siehe auch</a>)</li>
<li>Bearbeite <a href="http://www.tensorflow.org/tutorials/mnist/beginners/index.html">MNIST For ML Beginners</a> tutorial</li>
<li>Registriere bei Kaggle, und bearbeite <a href="https://www.kaggle.com/c/digit-recognizer">Digit Recognizer task</a>. Modifiziere dazu die Implementation von Schritt&nbsp;4</li>
</ol>
<h2 id="funftes-treffen_1">F&uuml;nftes Treffen</h2>
<figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/woman_bb.png" style="float:right;" width="256">
<figcaption style="display:table-caption;caption-side:bottom"><br/>
Lokalisierung eines Kopfes.</figcaption>
</img></figure>
<ul>
<li>Datum: 16.12.2015, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: Overfeat: Objektlokalisierung mit CNNs</li>
<li>Experte: Michael&nbsp;Weber</li>
</ul>
<p>Overfeat erm&ouml;glicht es Objecte (z.b. Autos) auf Bildern zu lokalisieren. Die Aufgabe ist es eine Bounding-Box um das zu Lokalisierende Objekt zu zeichnen.</p>
<h3 id="vorbereitung_4">Vorbereitung</h3>
<p>Besch&auml;ftigt euch im Vorfeld mit Overfeat:</p>
<ol>
<li><a href="http://arxiv.org/abs/1312.6229">Overfeat</a></li>
</ol>
<p>Laut Michael ist die Quelle sehr Umfrangreich. Wir werden in der PDG also vermutlich nicht ganz durchkommen. Wer es also nicht schafft das gesammte Paper zu lesen kann trotzdem gerne vorbeikommen.</p>
<h2 id="sechstes-treffen_1">Sechstes Treffen</h2>
<figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/arma.png" style="float:right;" width="256">
<figcaption style="display:table-caption;caption-side:bottom"><br/>
Lokalisierung von K&ouml;pfen.</figcaption>
</img></figure>
<ul>
<li>Datum: 21.12.2015, 16:15</li>
<li>Ort:  KIT Biblothek (30.50) R31 (Medienzentrum)</li>
<li>Thema: Overfeat2: Localization and Detection</li>
<li>Experte: Michael&nbsp;Weber</li>
</ul>
<p>Wir besprechen Sektion 4 und 5 von Overfeat.</p>
<h3 id="vorbereitung_5">Vorbereitung</h3>
<p>Besch&auml;ftigt euch im Vorfeld mit Overfeat:</p>
<ol>
<li><a href="http://arxiv.org/abs/1312.6229">Overfeat</a></li>
</ol>
<h2 id="siebtes-treffen_1">Siebtes Treffen</h2>
<figure style="display:table;float:right">
<img align="middle" class="img-responsive" src="//ml-ka.de/images/horse640_final.png" style="float:right;" width="256">
<figcaption style="display:table-caption;caption-side:bottom"><br/>
Segmentierung eines Bildes.</figcaption>
</img></figure>
<ul>
<li>Datum: 13.01.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: Fully Convolutional Networks for Semantic Segmentation</li>
<li>Experte: Marvin&nbsp;Teichmann</li>
</ul>
<p>In dem n&auml;chsten Treffen verstehen wir die FCNs welche Long und Shelhammer auf der CVPR 2015 vorgestellt haben. Diese haben innerhalb weniger Monate viel Aufmerksamkeit erhalten und wurden in kurzer Zeit bereits fast 200 mal zitiert.</p>
<h3 id="vorbereitung_6">Vorbereitung</h3>
<p>Lest bitte im Vorfeld das folgende Paper:</p>
<ol>
<li><a href="http://www.cs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">Fully Convolutional Networks for Semantic Segmentation</a>,
   <em>Jon Long and Evan Shelhamer et. al</em> (<strong>CVPR2015</strong>)</li>
</ol>
<h2 id="achtes-treffen_1">Achtes Treffen</h2>
<ul>
<li>Datum: 20.01.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></li>
<li>Experte: Leonard&nbsp;Lausen</li>
</ul>
<h2 id="neuntes-treffen">Neuntes Treffen</h2>
<ul>
<li>Datum: 27.01.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://arxiv.org/abs/1406.6247">Recurrent Models of Visual Attention</a></li>
<li>Experte: Leonard&nbsp;Lausen</li>
</ul>
<p>Bei dem Treffen wurden folgende Paper f&uuml;r weitere Treffen vorgeschlagen:</p>
<ul>
<li><a href="http://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning</a><ul>
<li><a href="http://arxiv.org/abs/1511.06342">Actor mimic: Deep multitask and transfer reinforcement learning</a></li>
</ul>
</li>
<li><a href="http://arxiv.org/pdf/1502.03044v2.pdf">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a> (Soft attention)</li>
<li><a href="http://arxiv.org/abs/1411.1792">How transferable are features in deep neural networks</a></li>
<li>Knowledge transfer<ul>
<li><a href="http://arxiv.org/abs/1504.04871">DEEP-CARVING: Discovering Visual Attributes by Carving Deep Neural Nets</a></li>
<li><a href="http://arxiv.org/abs/1506.00511">Predicting Deep Zero-Shot Convolutional Neural Networks using Textual Descriptions</a></li>
<li><a href="http://arxiv.org/abs/1502.02791">Learning Transferable Features with Deep Adaptation Networks</a></li>
</ul>
</li>
</ul>
<h2 id="zehntes-treffen">Zehntes Treffen</h2>
<ul>
<li>Datum: 03.02.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
<li>Experte: Martin&nbsp;Thoma (<a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/HeZRS15#MartinThoma">Zusammenfassung</a>)</li>
</ul>
<p>Going Deeper - mal wieder. In dem Paper wird ein Netz vorgestellt, welches
bei ILSVRC deutlich besser ist als die vorherigen Resultate.</p>
<h2 id="elftes-treffen">Elftes Treffen</h2>
<ul>
<li>Datum: 10.02.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://arxiv.org/abs/1502.03044">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>
<li>Experte: Leonard&nbsp;Lausen</li>
</ul>
<h2 id="zwolftes-treffen">Zw&ouml;lftes Treffen</h2>
<ul>
<li>Datum: 17.02.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://arxiv.org/pdf/1505.05192v3.pdf">Unsupervised Visual Representation Learning by Context Prediction</a></li>
<li>Experte: Andrey&nbsp;Yegorov</li>
</ul>
<h1 id="13-treffen_1">13. Treffen</h1>
<ul>
<li>Datum: 24.02.2016, 17:30</li>
<li>Ort:  Seminarraum: -107, Infobau (Geb. 50.34)</li>
<li>Thema: <a href="http://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning</a></li>
<li>Experte: Marvin&nbsp;Teichmann</li>
</ul>
            </div>
            <!-- /.entry-content -->
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>

<section class="well well-sm">
    <ul class="list-group list-group-flush">
            <li class="list-group-item"><h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
              <ul class="list-group" id="social">
                <li class="list-group-item"><a href="https://www.facebook.com/mlkarlsruhe"><i class="fa fa-facebook-square fa-lg"></i> Facebook</a></li>
              </ul>
            </li>





    <li class="list-group-item"><h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
      <ul class="list-group" id="links">
        <li class="list-group-item">
            <a href="https://github.com/ML-KA/" target="_blank">
                GitHub/ML-KA
            </a>
        </li>
      </ul>
    </li>
    </ul>
</section>
            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2016 Members of the ML-KA group
            &middot; Powered by <a href="https://github.com/DandyDev/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="//ml-ka.de/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="//ml-ka.de/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="//ml-ka.de/theme/js/respond.min.js"></script>


</body>
</html>